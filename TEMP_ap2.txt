    ci: float = 0.68,
    overlay_synth: bool = False,
    peers: Iterable[str] | None = None,
    weights: Optional[Mapping[str, float]] = None,
    overlay_peers: bool = False,
    max_expiries: int = 6,
) -> Dict[str, Any]:
    """
    Precompute smile data and fitted parameters for plotting (optimized).

    Perf notes:
    - Single pass conversion to NumPy, group by expiry once.
    - Optional subsample per-expiry to cap solver work while preserving shape.
    - Skip overlay surface building unless overlay_synth or overlay_peers is True.
    - Avoid re-reading params cache per expiry.
    """
    peers = list(peers or [])
    asof_ts = pd.to_datetime(asof).normalize()

    # ---- param cache (one filter) -----------------------------------------
    try:
        from .model_params_logger import append_params, load_model_params
        params_cache = load_model_params()
        if not params_cache.empty:
            params_cache = params_cache[
                (params_cache["ticker"] == target)
                & (params_cache["asof_date"] == asof_ts)
                & (params_cache["model"].isin(["svi", "sabr", "tps", "sens"]))
            ]
    except Exception:
        append_params = None  # type: ignore
        params_cache = pd.DataFrame()

    # ---- quotes for one day (at most max_expiries expiries) ---------------
    df = get_smile_slice(target, asof, T_target_years=None, max_expiries=max_expiries)
    if df is None or df.empty:
        return {}

    # Light, one-time coercions
    # Keep a pre-sorted view so per-expiry slices are contiguous
    df = df.sort_values(["expiry", "moneyness", "K"], kind="stable").reset_index(drop=True)
    # Convert columns once
    T_col = pd.to_numeric(df["T"], errors="coerce").to_numpy(dtype=float, copy=False)
    K_col = pd.to_numeric(df["K"], errors="coerce").to_numpy(dtype=float, copy=False)
    IV_col = pd.to_numeric(df["sigma"], errors="coerce").to_numpy(dtype=float, copy=False)
    S_col = pd.to_numeric(df["S"], errors="coerce").to_numpy(dtype=float, copy=False)
    expiry_col = pd.to_datetime(df.get("expiry"), errors="coerce").to_numpy(copy=False)

    # Unique expiries via stable grouping (vectorized)
    # Map each row to an expiry group id
    # (astype('datetime64[ns]') ensures exact equality within a day)
    exp_vals, inv = np.unique(expiry_col.astype("datetime64[ns]"), return_inverse=True)
    # Filter out NaT groups
    valid_grp = ~(exp_vals.astype("datetime64[ns]") == np.datetime64("NaT"))
    if not valid_grp.any():
        return {}

    # For target T, pick nearest expiry
    Ts_all = np.array([np.nanmedian(T_col[inv == g]) for g in range(len(exp_vals))], dtype=float)
    Ts = np.sort(Ts_all[np.isfinite(Ts_all)])
    if Ts.size == 0:
        return {}
    idx0 = int(np.argmin(np.abs(Ts * 365.25 - float(T_days))))
    T0 = float(Ts[idx0])

    # Helper: cached params by (tenor_d, model)
    def _cached(tenor_d: int, model_name: str) -> Optional[Dict[str, float]]:
        if params_cache is None or params_cache.empty:
            return None
        sub = params_cache[(params_cache["tenor_d"] == tenor_d) & (params_cache["model"] == model_name)]
        return None if sub.empty else sub.set_index("param")["value"].to_dict()

    # Optional uniform subsample per expiry to cap solver work
    # Set via env: PREPARE_SMILE_MAX_PER_EXP (e.g., 60). 0 disables.
    try:
        max_per_exp = int(os.environ.get("PREPARE_SMILE_MAX_PER_EXP", "0"))
    except Exception:
        max_per_exp = 0

    # Per-expiry fitting
    fit_by_expiry: Dict[float, Dict[str, Any]] = {}

    # Build an array of unique group ids sorted by their median T (so stable)
    grp_ids = np.argsort(Ts_all)
    for g in grp_ids:
        if not valid_grp[g]:
            continue
        row_mask = (inv == g)
        if not row_mask.any():
            continue

        # slice arrays once
        K = K_col[row_mask]
        IV = IV_col[row_mask]
        S_slice = S_col[row_mask]
        T_slice = T_col[row_mask]
        exp_dt = exp_vals[g]  # datetime64[ns] or NaT

        # basic sanity
        if K.size < 5 or not np.isfinite(IV).any():
            continue

        # robust S and single T for this expiry
        S = float(np.nanmedian(S_slice))
        T_val = float(np.nanmedian(T_slice))
        if not (np.isfinite(S) and np.isfinite(T_val)):
            continue

        # optional subsample uniformly in moneyness
        if max_per_exp and K.size > max_per_exp:
            with np.errstate(invalid="ignore", divide="ignore"):
                mny = K / S
            ord_idx = np.argsort(mny)
            sel = np.linspace(0, ord_idx.size - 1, num=max_per_exp, dtype=int)
            take = ord_idx[sel]
            K = K.take(take)
            IV = IV.take(take)

        expiry_dt = None
        try:
            # convert numpy datetime64 -> pandas Timestamp only once
            expiry_dt = pd.Timestamp(exp_dt) if str(exp_dt) != "NaT" else None
        except Exception:
            expiry_dt = None

        tenor_d = int((expiry_dt - asof_ts).days) if expiry_dt is not None else int(round(T_val * 365.25))

        # ---- fit models (pull from cache if available) --------------------
        svi_params = _cached(tenor_d, "svi")
        sabr_params = _cached(tenor_d, "sabr")
        tps_params = _cached(tenor_d, "tps")
        sens_params = _cached(tenor_d, "sens")

        # Lazy imports only when needed
        if svi_params is None:
            from volModel.sviFit import fit_svi_slice
            svi_params = fit_svi_slice(S, K, T_val, IV)
            if append_params:
                try:
                    append_params(asof, target, str(expiry_dt) if expiry_dt is not None else None,
                                  "svi", svi_params, meta={"rmse": svi_params.get("rmse")})
                except Exception:
                    pass

        if sabr_params is None:
            from volModel.sabrFit import fit_sabr_slice
            sabr_params = fit_sabr_slice(S, K, T_val, IV)
            if append_params:
                try:
                    append_params(asof, target, str(expiry_dt) if expiry_dt is not None else None,
                                  "sabr", sabr_params, meta={"rmse": sabr_params.get("rmse")})
                except Exception:
                    pass

        if tps_params is None:
            try:
                from volModel.polyFit import fit_tps_slice
                tps_params = fit_tps_slice(S, K, T_val, IV)
                if append_params:
                    append_params(asof, target, str(expiry_dt) if expiry_dt is not None else None,
                                  "tps", tps_params, meta={"rmse": tps_params.get("rmse")})
            except Exception:
                tps_params = {}

        if sens_params is None:
            # very cheap single-pass sensitivities - need S, T, K, sigma for _fit_smile_get_atm
            dfe = df.loc[row_mask, ["K", "S", "T", "sigma"]].copy()
            try:
                dfe["moneyness"] = dfe["K"].astype(float) / float(S)
            except Exception:
                dfe["moneyness"] = np.nan
            sens = _fit_smile_get_atm(dfe, model="auto")
            sens_params = {k: sens[k] for k in ("atm_vol", "skew", "curv") if k in sens}
            if append_params:
                try:
                    append_params(asof, target, str(expiry_dt) if expiry_dt is not None else None,
                                  "sens", sens_params)
                except Exception:
                    pass

        # ---- optional CI bands -------------------------------------------
        entry: Dict[str, Any] = {
            "svi": svi_params,
            "sabr": sabr_params,
            "tps": tps_params,
            "sens": sens_params,
            "expiry": str(expiry_dt) if expiry_dt is not None else None,
        }

        if ci and ci > 0:
            m_grid = np.linspace(0.7, 1.3, 121, dtype=float)
            K_grid = m_grid * S  # cheap scale
            bands_map: Dict[str, Bands] = {}
            try:
                bands_map["svi"] = svi_confidence_bands(S, K, T_val, IV, K_grid, level=float(ci))
            except Exception:
                pass
            try:
                bands_map["sabr"] = sabr_confidence_bands(S, K, T_val, IV, K_grid, level=float(ci))
            except Exception:
                pass
            try:
                bands_map["tps"] = tps_confidence_bands(S, K, T_val, IV, K_grid, level=float(ci))
            except Exception:
                pass
            if bands_map:
                entry["bands"] = bands_map

        fit_by_expiry[T_val] = entry

    # pick the nearest fitted expiry info
    fit_entry = fit_by_expiry.get(T0, {})
    fit_info = {
        "ticker": target,
        "asof": asof,
        "expiry": fit_entry.get("expiry"),
        "svi": fit_entry.get("svi", {}),
        "sabr": fit_entry.get("sabr", {}),
        "tps": fit_entry.get("tps", {}),
        "sens": fit_entry.get("sens", {}),
    }

    # ---- optional overlays (do work only if requested) ---------------------
    tgt_surface = None
    syn_surface = None
    if (overlay_synth or overlay_peers) and peers:
        try:
            tickers = list({target, *peers})
            surfaces = build_surface_grids(
                tickers=tickers, use_atm_only=False, max_expiries=max_expiries
            )
            if target in surfaces and asof in surfaces[target]:
                tgt_surface = surfaces[target][asof]

            if overlay_synth:
                peer_surfaces = {p: surfaces[p] for p in peers if p in surfaces and asof in surfaces[p]}
                if peer_surfaces:
                    w = ({p: float(weights.get(p, 1.0)) for p in peer_surfaces}
                         if weights else {p: 1.0 for p in peer_surfaces})
                    synth_by_date = combine_surfaces(peer_surfaces, w)
                    syn_surface = synth_by_date.get(asof)
        except Exception:
            tgt_surface = None
            syn_surface = None

    # Optional peer smile overlays (uses same max_expiries cap)
    peer_slices: Dict[str, Dict[str, np.ndarray]] = {}
    if overlay_peers and peers:
        for p in peers:
            df_p = get_smile_slice(p, asof, T_target_years=None, max_expiries=max_expiries)
            if df_p is None or df_p.empty:
                continue
            T_p = pd.to_numeric(df_p["T"], errors="coerce").to_numpy(float, copy=False)
            K_p = pd.to_numeric(df_p["K"], errors="coerce").to_numpy(float, copy=False)
            sigma_p = pd.to_numeric(df_p["sigma"], errors="coerce").to_numpy(float, copy=False)
            S_p = pd.to_numeric(df_p["S"], errors="coerce").to_numpy(float, copy=False)
            peer_slices[p.upper()] = {"T_arr": T_p, "K_arr": K_p, "sigma_arr": sigma_p, "S_arr": S_p}

    # Return the raw arrays from the (already converted) columns
    return {
        "T_arr": T_col,
        "K_arr": K_col,
        "sigma_arr": IV_col,
        "S_arr": S_col,
        "Ts": Ts,
        "idx0": idx0,
        "tgt_surface": tgt_surface,
        "syn_surface": syn_surface,
        "peer_slices": peer_slices,
        "expiry_arr": expiry_col,
        "fit_info": fit_info,
        "fit_by_expiry": fit_by_expiry,
    }

def normalize_ci_level(ci, default: float = 0.68) -> Optional[float]:
    """Normalize user-provided CI into (0,1) or return None.

    Rules:
    - None or falsy -> None
    - >1 and <=100 treated as percentage (e.g. 95 -> 0.95)
    - >100 or <=0 -> fallback to default (0.95)
    - Returns float in (0,1)
    """
    DEFAULT_CI_LEVEL = default if (0.0 < default < 1.0) else 0.68
    if ci is None:
        return None
    try:
        c = float(ci)
    except Exception:
        return DEFAULT_CI_LEVEL
    if c > 1.0:
        if c <= 100.0:
            c = c / 100.0
        else:
            return DEFAULT_CI_LEVEL
    if not (0.0 < c < 1.0):
        return DEFAULT_CI_LEVEL
    return c

def prepare_term_data(
    target: str,
    asof: str,
    ci: float = 68.0,
    peers: Iterable[str] | None = None,
    weights: Optional[Mapping[str, float]] = None,
    atm_band: float = 0.05,
    max_expiries: int = 6,
    overlay_synth: bool = True,
    get_slice: Callable[[str, str, float, int], pd.DataFrame] = get_smile_slice,
) -> Dict[str, Any]:
    """
    Precompute ATM term structure (+ optional composite overlay) (optimized).

    Perf notes:
    - One call to get_smile_slice; no repeated conversions.
    - When aligning peers, uses vectorized nearest-neighbor within tolerance.
    - Skips bootstraps entirely when ci==0.
    """
    ci = normalize_ci_level(ci)
    df_all = get_smile_slice(target, asof, T_target_years=None, max_expiries=max_expiries)
